---
title: "Indicator Normalizations"
output: html_document
date: "2022-11-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(janitor)
```

# Surf Spots

```{r}
ws_sl_surf <- read_csv(here("data", "ws_sl.csv")) %>% 
  clean_names()
```

```{r}
ws_sl_surf_na <- ws_sl_surf %>% 
  mutate(quality = case_when(
    quality == 0.0 ~ ,
    quality == 5.0 ~ "5.0",
    quality == 4.0 ~ "4.0",
    quality == 3.5 ~ "3.5",
    quality == 3.0 ~ "3.0",
    quality == 2.0 ~ "2.0"
  )) %>% 
  mutate(frequency = case_when(
    frequency == 0 ~ "NA",
    frequency == 5 ~ "5",
    frequency == 4 ~ "4",
    frequency == 3 ~ "3",
    frequency == 2 ~ "2",
    frequency == 1 ~ "1"
  ))
```

## Surf Spots Export

```{r}
write_csv(ws_sl_surf_na, file = "ws_sl_sys_spots.csv")
```

# Pressure Index

# Social Index

## Biodiversity Sub Index

## Surf Subindex

```{r}
# read in data
surf_indicators <- read_csv(here("data", "surf_indicators.csv")) %>% 
  select(-OBJECTID) %>% 
  clean_names()
```

### Surf Clusters

```{r}
max_cluster <- max(surf_indicators$join_count)
min_cluster <- min(surf_indicators$join_count)

cluster_normalized <- round((surf_indicators$join_count - min_cluster) / 
                              (max_cluster - min_cluster), 6)

surf_indicators$normalized_cluster <- cluster_normalized
```

### Direction

```{r}
surf_indicators$normalized_direction <- surf_indicators$numerical_direction
```

### Frequency

```{r}
max_frequency <- max(surf_indicators$numerical_frequency)
min_frequency <- min(surf_indicators$numerical_frequency)

frequency_normalized <- round((surf_indicators$numerical_frequency - min_frequency) / 
                                (max_frequency - min_frequency), 10)

surf_indicators$normalized_frequency <- frequency_normalized
```

### Experience

```{r}
surf_indicators$normalized_experience <- surf_indicators$numerical_experience
```

### Quality

```{r}
max_quality <- max(surf_indicators$numerical_quality)
min_quality <- min(surf_indicators$numerical_quality)

quality_normalized <- round((surf_indicators$numerical_quality - min_quality) / 
                              (max_quality - min_quality), 10)

surf_indicators$normalized_quality <- quality_normalized
```

## Surf Subindex Normalized

```{r}
normalized_added_indicators <- round(surf_indicators$normalized_quality + surf_indicators$normalized_experience +
                                       surf_indicators$normalized_frequency + surf_indicators$normalized_direction +
                                       surf_indicators$normalized_cluster, 10)

surf_indicators$added_normalized <- normalized_added_indicators

max_added <- max(surf_indicators$added_normalized)
min_added <- min(surf_indicators$added_normalized)

surf_normalized <- round((surf_indicators$added_normalized - min_added) / 
                           (max_added - min_added), 10)

surf_indicators$surf_subindex <- surf_normalized
```

```{r}
## Surf Subindex Indicators Export
# write_csv(surf_indicators, "surf_indicators_normalized.csv")
```

## Surf Subindex Export

```{r}
write_csv(surf_indicators, file = "surf_subindex.csv")
```

## Social Subindex

# Response Index

```{r}
heritage <- read_csv(here("data", "response", "heritage_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, world_heri) %>% 
  clean_names()
atl_for_priority <- read_csv(here("data", "response", "priority_area_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, protected_) %>% 
  clean_names()
guarda <- read_csv(here("data", "response", "wsr_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, wsr_percen) %>% 
  clean_names()
prot_areas <- read_csv(here("data", "response", "protected_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, protected_) %>% 
  clean_names()
bandeira <- read_csv(here("data", "response", "bandeira_surf.csv")) %>% 
  select(OBJECTID, Join_Count, Name, Surfline_n) %>% 
  clean_names()
ramsar <- read_csv(here("data", "response", "ramsar_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, ramsar_per) %>% 
  clean_names()
```

## World Heritage Sites

```{r}
max_heritage <- round(max(heritage$world_heri), 10)
min_heritage <- round(min(heritage$world_heri), 10)

heritage_normalized <- round((heritage$world_heri - min_heritage) / 
                               (max_heritage - min_heritage), 10)

heritage$normalized_heritage <- heritage_normalized
```

## Atlantic Forest Priority Areas

```{r}
max_priority <- round(max(atl_for_priority$protected), 10)
min_priority <- round(min(atl_for_priority$protected), 10)

priority_normalized <- round((atl_for_priority$protected - min_priority) / 
                               (max_priority - min_priority), 10)

atl_for_priority$normalized_priority <- priority_normalized
```

## Guarda World Surfing Reserve

```{r}
max_wsr <- round(max(guarda$wsr_percen), 10)
min_wsr <- round(min(guarda$wsr_percen), 10)

wsr_normalized <- round((guarda$wsr_percen - min_wsr) / 
                          (max_wsr - min_wsr), 10)

guarda$normalized_wsr <- wsr_normalized
```

## Protected Areas

```{r}
max_protected <- round(max(prot_areas$protected), 10)
min_protected <- round(min(prot_areas$protected), 10)

protected_normalized <- round((prot_areas$protected - min_protected) / 
                                (max_protected - min_protected), 10)

prot_areas$normalized_protected <- protected_normalized
```

## Bandeira Reserves

```{r}
max_join <- round(max(bandeira$join_count), 10)
min_join <- round(min(bandeira$join_count), 10)

bandeira_normalized <- round((bandeira$join_count - min_join) / 
                               (max_join - min_join), 10)

bandeira$normalized_bandeira <- bandeira_normalized
```

## Ramsar Sites

```{r}
max_ramsar <- round(max(ramsar$ramsar_per), 10)
min_ramsar <- round(min(ramsar$ramsar_per), 10)

ramsar_normalized <- round((ramsar$ramsar_per - min_ramsar) / 
                            (max_ramsar - min_ramsar), 10)

ramsar$normalized_ramsar <- ramsar_normalized
```

## Merge Response Index Indicators

```{r}
response_normalized <- merge(heritage, atl_for_priority,
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority)

response_normalized <- merge(response_normalized, guarda,
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr)

response_normalized <- merge(response_normalized, prot_areas, 
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr, 
         normalized_protected)

response_normalized <- merge(response_normalized, bandeira,
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr, 
         normalized_protected, normalized_bandeira)

response_normalized <- merge(response_normalized, ramsar, 
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr, 
         normalized_protected, normalized_bandeira, normalized_ramsar)
```

## Normalized Response Index

```{r}
# add column called response_added 
response_normalized <- response_normalized %>% 
  mutate(response_added = round(response_normalized$normalized_heritage + response_normalized$normalized_priority +
                        response_normalized$normalized_wsr + response_normalized$normalized_protected +
                        response_normalized$normalized_bandeira + response_normalized$normalized_ramsar, 10))

max_response_added <- round(max(response_normalized$response_added), 10)
min_response_added <- round(min(response_normalized$response_added), 10)

response_normalized <- response_normalized %>% 
  mutate(response_index = round((response_normalized$response_added - min_response_added) /
                              (max_response_added - min_response_added), 10))
```

## Response Index Export

```{r}
write_csv(response_normalized, file = "normalized_response.csv")
```

















