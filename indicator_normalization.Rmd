---
title: "Indicator Normalizations"
output: html_document
date: "2022-11-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(janitor)
```

# Surf Spots

```{r}
ws_sl_surf <- read_csv(here("data", "ws_sl.csv")) %>% 
  clean_names()
```

```{r}
ws_sl_surf_na <- ws_sl_surf %>% 
  mutate(quality = case_when(
    quality == 0.0 ~ ,
    quality == 5.0 ~ "5.0",
    quality == 4.0 ~ "4.0",
    quality == 3.5 ~ "3.5",
    quality == 3.0 ~ "3.0",
    quality == 2.0 ~ "2.0"
  )) %>% 
  mutate(frequency = case_when(
    frequency == 0 ~ "NA",
    frequency == 5 ~ "5",
    frequency == 4 ~ "4",
    frequency == 3 ~ "3",
    frequency == 2 ~ "2",
    frequency == 1 ~ "1"
  ))
```

## Surf Spots Export

```{r}
write_csv(ws_sl_surf_na, file = "ws_sl_sys_spots.csv")
```

# Pressure Index

# Social Index

## Biodiversity Sub Index

```{r}
marine_richness <- read_csv(here("data", "biodiversity", "marine_richness.csv")) %>% 
  clean_names()
terr_richness <- read_csv(here("data", "biodiversity", "terr_richness.csv")) %>% 
  clean_names()
coral <- read_csv(here("data", "biodiversity", "coral_reef.csv")) %>% 
  select(OBJECTID, Name, Surf_Spot, SUM_Area_S, coral_reef) %>% 
  clean_names()
mangrove <- read_csv(here("data", "biodiversity", "mangrove.csv")) %>% 
  select(OBJECTID, Name, Surf_Spot, SUM_Area_S, mangrove_p) %>% 
  clean_names()
seagrass <- read_csv(here("data", "biodiversity", "seagrass.csv")) %>% 
  select(OBJECTID, Join_Count, Name, Surf_Spot) %>% 
  clean_names()
tree_cover <- read_csv(here("data", "biodiversity", "tree_cover.csv")) %>% 
  clean_names()
terr_pa_high <- read_csv(here("data", "biodiversity", "terr_pa_high.csv")) %>% 
  clean_names()
terr_pa_ver_high <- read_csv(here("data", "biodiversity", "terr_pa_very_high.csv")) %>% 
  clean_names()
terr_pa_ext_high <- read_csv(here("data", "biodiversity", "terr_pa_extremely_high.csv")) %>% 
  clean_names()
ocean_pa <- read_csv(here("data", "biodiversity", "oceanic_pa.csv")) %>% 
  clean_names()
```

### Species Biodiversity

```{r}
# terrestrial species
max_terr_rich <- round(max(terr_richness$mean), 10)
min_terr_rich <- round(min(terr_richness$mean), 10)

terr_richness <- terr_richness %>% 
  mutate(normalized_terr_rich = round((mean - min_terr_rich) / 
                                        (max_terr_rich - min_terr_rich), 10))

# marine species
max_marine_rich <- round(max(marine_richness$mean), 10)
min_marine_rich <- round(min(marine_richness$mean), 10)

marine_richness <- marine_richness %>% 
  mutate(normalized_mar_rich = round((mean - min_marine_rich) /
                                       (max_marine_rich - min_marine_rich), 10))
```

### Ecosystem Biodiversity

```{r}
# marine ecosystems

```

#### Marine Ecosystem Biodiversity Weighted

```{r}

```

### Priority Areas (& Weighted)

```{r}

```

### Merge Biodiversity Indicators

```{r}

```

### Normalize Biodiversity Subindex

```{r}

```

### Export Normalized Biodiverstiy Subindex

```{r}

```

## Surf Subindex

```{r}
# read in data
surf_indicators <- read_csv(here("data", "surf_indicators.csv")) %>% 
  select(-OBJECTID) %>% 
  clean_names()
```

### Surf Clusters

```{r}
max_cluster <- max(surf_indicators$join_count)
min_cluster <- min(surf_indicators$join_count)

cluster_normalized <- round((surf_indicators$join_count - min_cluster) / 
                              (max_cluster - min_cluster), 6)

surf_indicators$normalized_cluster <- cluster_normalized
```

### Direction

```{r}
surf_indicators$normalized_direction <- surf_indicators$numerical_direction
```

### Frequency

```{r}
max_frequency <- max(surf_indicators$numerical_frequency)
min_frequency <- min(surf_indicators$numerical_frequency)

frequency_normalized <- round((surf_indicators$numerical_frequency - min_frequency) / 
                                (max_frequency - min_frequency), 10)

surf_indicators$normalized_frequency <- frequency_normalized
```

### Experience

```{r}
surf_indicators$normalized_experience <- surf_indicators$numerical_experience
```

### Quality

```{r}
max_quality <- max(surf_indicators$numerical_quality)
min_quality <- min(surf_indicators$numerical_quality)

quality_normalized <- round((surf_indicators$numerical_quality - min_quality) / 
                              (max_quality - min_quality), 10)

surf_indicators$normalized_quality <- quality_normalized
```

## Surf Subindex Normalized

```{r}
normalized_added_indicators <- round(surf_indicators$normalized_quality + surf_indicators$normalized_experience +
                                       surf_indicators$normalized_frequency + surf_indicators$normalized_direction +
                                       surf_indicators$normalized_cluster, 10)

surf_indicators$added_normalized <- normalized_added_indicators

max_added <- max(surf_indicators$added_normalized)
min_added <- min(surf_indicators$added_normalized)

surf_normalized <- round((surf_indicators$added_normalized - min_added) / 
                           (max_added - min_added), 10)

surf_indicators$surf_subindex <- surf_normalized
```

```{r}
## Surf Subindex Indicators Export
# write_csv(surf_indicators, "surf_indicators_normalized.csv")
```

## Surf Subindex Export

```{r}
write_csv(surf_indicators, file = "surf_subindex.csv")
```

## Social Subindex

```{r}
employment <- read_csv(here("data", "social", "SLR_employment.csv")) %>% 
  select(OBJECTID, Join_Count, Name, Surf_Spot, SLR_employ) %>% 
  clean_names()
hotels <- read_csv(here("data", "social", "hotels.csv")) %>% 
  select(OBJECTID, Join_Count, Name, Surf_Spot) %>% 
  clean_names()
airports <- read_csv(here("data", "social", "airports.csv")) %>% 
  select(OBJECTID, Join_Count, Name, Surf_Spot) %>% 
  clean_names()
```

### Employment

```{r}
max_employment <- round(max(employment$slr_employ), 10)
min_employment <- round(min(employment$slr_employ), 10)

employment <- employment %>% 
  mutate(normalized_employment = round((employment$slr_employ - min_employment) /
                                         (max_employment - min_employment), 10))
```

### Hotels

```{r}
max_hotel <- round(max(hotels$join_count), 10)
min_hotel <- round(min(hotels$join_count), 10)

hotels <- hotels %>% 
  mutate(normalized_hotels = round((hotels$join_count - min_hotel) /
                                     (max_hotel - min_hotel), 10))
```

### Airports

```{r}
max_airport <- round(max(airports$join_count), 10)
min_airport <- round(min(airports$join_count), 10)

airports <- airports %>% 
  mutate(normalized_airports = round((airports$join_count - min_airport) /
                                       (max_airport - min_airport), 10))
```

### Merge Social Index Indicators

```{r}
social_normalized <- left_join(employment, hotels, 
                               by = "objectid") %>% 
  select(objectid, name.x, surf_spot.x, 
         normalized_employment, normalized_hotels)

social_normalized <- left_join(social_normalized, airports,
                               by = "objectid") %>% 
  select(objectid, name.x, surf_spot.x, 
         normalized_employment, normalized_hotels, normalized_airports)
```

### Normalized Social Subindex

```{r}
social_normalized <- social_normalized %>% 
  mutate(social_added = round(normalized_employment + normalized_hotels + normalized_airports, 10))

max_social_added <- round(max(social_normalized$social_added), 10)
min_social_added <- round(min(social_normalized$social_added), 10)

social_normalized <- social_normalized %>% 
  mutate(social_subindex = round((social_normalized$social_added - min_social_added) /
                                   (max_social_added - min_social_added), 10))
```

### Export Social Subindex

```{r}
write_csv(social_normalized, file = "normalized_social.csv")
```

# Response Index

```{r}
heritage <- read_csv(here("data", "response", "heritage_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, world_heri) %>% 
  clean_names()
atl_for_priority <- read_csv(here("data", "response", "priority_area_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, protected_) %>% 
  clean_names()
guarda <- read_csv(here("data", "response", "wsr_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, wsr_percen) %>% 
  clean_names()
prot_areas <- read_csv(here("data", "response", "protected_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, protected_) %>% 
  clean_names()
bandeira <- read_csv(here("data", "response", "bandeira_surf.csv")) %>% 
  select(OBJECTID, Join_Count, Name, Surfline_n) %>% 
  clean_names()
ramsar <- read_csv(here("data", "response", "ramsar_surf.csv")) %>% 
  select(OBJECTID, Name, Surfline_n, Shape_Leng, Shape_Area, SUM_Area_S, ramsar_per) %>% 
  clean_names()
```

## World Heritage Sites

```{r}
max_heritage <- round(max(heritage$world_heri), 10)
min_heritage <- round(min(heritage$world_heri), 10)

heritage_normalized <- round((heritage$world_heri - min_heritage) / 
                               (max_heritage - min_heritage), 10)

heritage$normalized_heritage <- heritage_normalized
```

## Atlantic Forest Priority Areas

```{r}
max_priority <- round(max(atl_for_priority$protected), 10)
min_priority <- round(min(atl_for_priority$protected), 10)

priority_normalized <- round((atl_for_priority$protected - min_priority) / 
                               (max_priority - min_priority), 10)

atl_for_priority$normalized_priority <- priority_normalized
```

## Guarda World Surfing Reserve

```{r}
max_wsr <- round(max(guarda$wsr_percen), 10)
min_wsr <- round(min(guarda$wsr_percen), 10)

wsr_normalized <- round((guarda$wsr_percen - min_wsr) / 
                          (max_wsr - min_wsr), 10)

guarda$normalized_wsr <- wsr_normalized
```

## Protected Areas

```{r}
max_protected <- round(max(prot_areas$protected), 10)
min_protected <- round(min(prot_areas$protected), 10)

protected_normalized <- round((prot_areas$protected - min_protected) / 
                                (max_protected - min_protected), 10)

prot_areas$normalized_protected <- protected_normalized
```

## Bandeira Reserves

```{r}
max_join <- round(max(bandeira$join_count), 10)
min_join <- round(min(bandeira$join_count), 10)

bandeira_normalized <- round((bandeira$join_count - min_join) / 
                               (max_join - min_join), 10)

bandeira$normalized_bandeira <- bandeira_normalized
```

## Ramsar Sites

```{r}
max_ramsar <- round(max(ramsar$ramsar_per), 10)
min_ramsar <- round(min(ramsar$ramsar_per), 10)

ramsar_normalized <- round((ramsar$ramsar_per - min_ramsar) / 
                            (max_ramsar - min_ramsar), 10)

ramsar$normalized_ramsar <- ramsar_normalized
```

## Merge Response Index Indicators

```{r}
response_normalized <- merge(heritage, atl_for_priority,
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority)

response_normalized <- merge(response_normalized, guarda,
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr)

response_normalized <- merge(response_normalized, prot_areas, 
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr, 
         normalized_protected)

response_normalized <- merge(response_normalized, bandeira,
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr, 
         normalized_protected, normalized_bandeira)

response_normalized <- merge(response_normalized, ramsar, 
                             by = "objectid") %>% 
  select(objectid, name.x, surfline_n.x, 
         normalized_heritage, normalized_priority, normalized_wsr, 
         normalized_protected, normalized_bandeira, normalized_ramsar)
```

## Normalized Response Index

```{r}
# add column called response_added 
response_normalized <- response_normalized %>% 
  mutate(response_added = round(response_normalized$normalized_heritage + response_normalized$normalized_priority +
                        response_normalized$normalized_wsr + response_normalized$normalized_protected +
                        response_normalized$normalized_bandeira + response_normalized$normalized_ramsar, 10))

max_response_added <- round(max(response_normalized$response_added), 10)
min_response_added <- round(min(response_normalized$response_added), 10)

response_normalized <- response_normalized %>% 
  mutate(response_index = round((response_normalized$response_added - min_response_added) /
                              (max_response_added - min_response_added), 10))
```

## Response Index Export

```{r}
write_csv(response_normalized, file = "normalized_response.csv")
```

















